# <span><strong> Welcome, this is my resume </strong></span>

## <span style="color:red"> 0. Contact info and online profiles </span>

- Email: lucas.svmariano@gmail.com
- [Github](https://github.com/lukemariano)
- [Linkedin](https://www.linkedin.com/in/lucas-mariano-da-silva-luke/)
- [Instagram](https://www.instagram.com/iamlukas_silva/)

## <span style="color:red"> 1. A little about myself </span>

> ‚ÄúWe‚Äôre here to put a dent in the universe. Otherwise why else even be here?‚Äù - Steve Jobs

Helloüëã, my name is Lucas Mariano da Silva and I'm 20 years old.

The quote above describes well one of my main motivations, which is related to being able to one day be part of a big project and be able to leave my mark on the world.

This means that I consider myself a person who really likes challenges (and pizza). I like the feeling of always being on the move, learning new things, traveling to different places and making new friends. After all, to live is to be on the moveüßóüèΩ

### <span style="color:red"> 1.1 My first contact with technology üë®‚Äçüíª </span>

I have been passionate about programming since I was 15 years old. I remember how fun it was to write my first "Hello World!" in java.

I could spend hours and hours in front of the computer üíª without even seeing time pass.

I have a lot to thank Etec from Ilha Solteira and the excellent teachers for giving me an excellent foundation of programming logic, java, C, C#, pascal and SQL.

## <span style="color:red"> 2. My skills </span>

Currently I have focused more and more on developing skills related to data science, such as:

- SQL;
- Python üêç;
- Pandas;
- Pyspark;
- Statistics and Probability;
- Machine Learning;

However, I also have programming skills using the following programming languages, markup languages ‚Äã‚Äãand frameworks:

- Javascript;
- Vuejs;
- HTML/CSS;
- Django;

I also master the following tools:

- GIT;
- Gitlab;
- Databricks;
- Apache Airflow;
- Metabase;
- Jupyter;
- Docker;
- Starllete (in progress);
- Kubernetes (in progress);

## <span style="color:red"> 3. Academic education </span>

<strong> ETEC from Ilha Solteira | High School llong with technical education:</strong>

- Computer Technician (2017 - 2019)

<strong> Descomplica | Cloud Computing: </strong>

- [Higher Technology Course (HST)](https://descomplica.com.br/faculdade/tecnologia/computacao-em-nuvem/) - graduation in progress

## <span style="color:red"> 4. What I am able to do: </span>

- Data cleaning and processing;
- Advanced data analysis with statistics;
- Advanced queries with SQL;
- Generate charts and dashboards;
- Static and dynamic websites;
- API calls and API development;
- Backend: data processing and processing;
- Building pipelines with python;

## <span style="color:red"> 5. Work Experience </span>

### <span style="color:red"> 5.1 Busertech program (april/2022 - present) </span>

At the end of 2021, I participated in a selection process by the company Buser regarding a [program to train fullstack developers.](https://blog.buser.com.br/novidades/buser-lanca-programa-capacitacao-profissionais-tecnologia/)

After a rigorous selection process with more than 5,000 candidates, I was among the 40 selected and I have been in the program for 9 months, working especially in the data science area, solving real problems on a daily basis, delivering results and contributing to the development of the company. It has been an amazing experience!

The objective of the program is to combine academic knowledge with learning that is obtained on a day-to-day basis as a developer in the company. With the busertech program we have the best of both worlds: theoretical and practical knowledge solving real day-to-day company problems.

### <span style="color:red"> 5.2 Data Science </span>

After 7 months of intense training as a fullstack at Buser, I started working with the company's data science team, where I have been working on solving real problems related to data science.

I have carried out exploratory analyzes for decision-making, monitoring the creation and deployment of machine learning models, scraping using the Scrapy and BeautifulSoup library and assisting in the creation of the front-end for displaying artifacts generated by machine learning models, in addition to having acted soon with the company's data engineering team.
